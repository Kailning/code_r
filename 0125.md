## 多道程序与分时多任务
#### 目标
实现分时多任务系统，它能并发地执行多个用户程序，并调度这些程序。
+ 一次性加载所有用户程序，减少任务切换开销；
+ 支持任务切换机制，保存切换前后程序上下文；
+ 支持程序主动放弃处理器，实现 yield 系统调用；
+ 以时间片轮转算法调度用户程序，实现资源的时分复用。
### 多道程序放置与加载
#### 多道程序放置
要一次加载运行多个程序，要求每个用户程序被内核加载到内存中的起始地址都不同。 为此，编写脚本 user/build.py 为每个应用定制各自的起始地址。对于每一个应用程序，使用 cargo rustc 单独编译， 用 -Clink-args=-Ttext=xxxx 选项指定链接时 .text 段的地址为 0x80400000 + app_id * 0x20000 。
#### 多道程序加载
在第二章中负责应用加载和执行的子模块 batch 被拆分为 loader 和 task ， 前者负责启动时加载应用程序，后者负责切换和调度。
其中， loader 模块的 load_apps 函数负责将所有用户程序在内核初始化的时一并加载进内存。
```
 1 // os/src/loader.rs
 2
 3 pub fn load_apps() {
 4     extern "C" {
 5         fn _num_app();
 6     }
 7     let num_app_ptr = _num_app as usize as *const usize;
 8     let num_app = get_num_app();
 9     let app_start = unsafe { core::slice::from_raw_parts(num_app_ptr.add(1), num_app + 1) };
10     // clear i-cache first
11     unsafe {
12         core::arch::asm!("fence.i");
13     }
14     // load apps
15     for i in 0..num_app {
16         let base_i = get_base_i(i);
17         // clear region
18         (base_i..base_i + APP_SIZE_LIMIT)
19             .for_each(|addr| unsafe { (addr as *mut u8).write_volatile(0) });
20         // load app from data section to memory
21         let src = unsafe {
22             core::slice::from_raw_parts(app_start[i] as *const u8, app_start[i + 1] - app_start[i])
23         };
24         let dst = unsafe { core::slice::from_raw_parts_mut(base_i as *mut u8, src.len()) };
25         dst.copy_from_slice(src);
26     }
27 }
```
第i个应用被加载到以物理地址 base_i 开头的一段物理内存上，而 base_i 的计算方式如下：
```
1 // os/src/loader.rs
2
3 fn get_base_i(app_id: usize) -> usize {
4     APP_BASE_ADDRESS + app_id * APP_SIZE_LIMIT
5 }
```
可以在 config 子模块中找到这两个常数， APP_BASE_ADDRESS 被设置为 0x80400000 ， 而 APP_SIZE_LIMIT 和上一章一样被设置为 0x20000 。这种放置方式与 user/build.py 的实现一致。
### 任务切换
\*\*操作系统的核心机制 ， 即应用在运行中主动或被动地交出 CPU 的使用权，内核可以选择另一个程序继续执行。 内核需要保证用户程序两次运行期间，任务上下文（如寄存器、栈等）保持一致。
#### 与上一章的 Trap 控制流切换相比，有如下异同：
+ 不同:不涉及特权级切换，部分由编译器完成；
+ 相同:它对应用是透明的。

任务切换是来自两个不同应用在内核中的 Trap 控制流之间的切换。 当一个应用 Trap 到 S 态 OS 内核中进行进一步处理时， 其 Trap 控制流可以调用一个特殊的 __switch 函数。 在 __switch 返回之后，Trap 控制流将继续从调用该函数的位置继续向下执行。而在调用 __switch 之后到返回前的这段时间里， 原 Trap 控制流 A 会先被暂停并被切换出去， CPU 转而运行另一个应用的 Trap 控制流 B 。 __switch 返回之后，原 Trap 控制流 A 才会从某一条 Trap 控制流 C 切换回来继续执行。 

需要在 __switch 中保存 CPU 的某些寄存器——任务上下文 (Task Context)
```
 1# os/src/task/switch.S
 2
 3.altmacro
 4.macro SAVE_SN n
 5    sd s\n, (\n+2)*8(a0)
 6.endm
 7.macro LOAD_SN n
 8    ld s\n, (\n+2)*8(a1)
 9.endm
10    .section .text
11    .globl __switch
12__switch:
13    # __switch(
14    #     current_task_cx_ptr: *mut TaskContext,
15    #     next_task_cx_ptr: *const TaskContext
16    # )
17    # save kernel stack of current task
18    sd sp, 8(a0)
19    # save ra & s0~s11 of current execution
20    sd ra, 0(a0)
21    .set n, 0
22    .rept 12
23        SAVE_SN %n
24        .set n, n + 1
25    .endr
26    # restore ra & s0~s11 of next execution
27    ld ra, 0(a1)
28    .set n, 0
29    .rept 12
30        LOAD_SN %n
31        .set n, n + 1
32    .endr
33    # restore kernel stack of next task
34    ld sp, 8(a1)
35    ret
```
它的两个参数分别是当前和即将被切换到的 Trap 控制流的 task_cx_ptr ，从 RISC-V 调用规范可知，它们分别通过寄存器 a0/a1 传入。内核先把 current_task_cx_ptr 中包含的寄存器值逐个保存，再把 next_task_cx_ptr 中包含的寄存器值逐个恢复。

TaskContext 里包含的寄存器有：
```
1// os/src/task/context.rs
2#[repr(C)]
3pub struct TaskContext {
4    ra: usize,
5    sp: usize,
6    s: [usize; 12],
7}
```
s0~s11 是被调用者保存寄存器， __switch 是用汇编编写的，编译器不会处理这些寄存器。  ra 记录了 __switch 函数返回之后应该跳转到哪里继续执行。

将这段汇编代码 __switch 解释为一个 Rust 函数：
```
1// os/src/task/switch.rs
2
3core::arch::global_asm!(include_str!("switch.S"));
4
5extern "C" {
6    pub fn __switch(
7        current_task_cx_ptr: *mut TaskContext,
8        next_task_cx_ptr: *const TaskContext);
9}
```
调用该函数来完成切换功能，在调用前后，编译器会保存和恢复调用者保存寄存器。
### 管理多道程序
内核为了管理任务，需要维护任务信息：
+ 任务运行状态：未初始化、准备执行、正在执行、已退出
+ 任务控制块：维护任务状态和任务上下文
+ 任务相关系统调用：程序主动暂停 sys_yield 和主动退出 sys_exit
#### yield 系统调用
![image-5](https://github.com/Kalining/code_repository/assets/148835940/8e18b25f-2fac-4c83-81a1-f61667c8bddb)

开始时，蓝色应用向外设提交了一个请求，外设随即开始工作， 但是它要一段时间后才能返回结果。蓝色应用于是调用 sys_yield 交出 CPU 使用权， 内核让绿色应用继续执行。一段时间后 CPU 切换回蓝色应用，发现外设仍未返回结果， 于是再次 sys_yield 。直到第二次切换回蓝色应用，外设才处理完请求，于是蓝色应用终于可以向下执行了。

\*\*调用 sys_yield 可以避免等待过程造成的资源浪费。

第三章新增系统调用（一）
```
/// 功能：应用主动交出 CPU 所有权并切换到其他应用。
/// 返回值：总是返回 0。
/// syscall ID：124
fn sys_yield() -> isize;
```
用户库对应的实现和封装：
```
// user/src/syscall.rs

pub fn sys_yield() -> isize {
    syscall(SYSCALL_YIELD, [0, 0, 0])
}

// user/src/lib.rs
// yield 是 Rust 的关键字
pub fn yield_() -> isize { sys_yield() }
```
#### 任务控制块与任务运行状态
任务运行状态暂包括如下几种：
```
1// os/src/task/task.rs
2
3#[derive(Copy, Clone, PartialEq)]
4pub enum TaskStatus {
5    UnInit, // 未初始化
6    Ready, // 准备运行
7    Running, // 正在运行
8    Exited, // 已退出
9}
```
任务状态外和任务上下文一并保存在名为 任务控制块 (Task Control Block) 的数据结构中：
```
1// os/src/task/task.rs
2
3#[derive(Copy, Clone)]
4pub struct TaskControlBlock {
5    pub task_status: TaskStatus,
6    pub task_cx: TaskContext,
7}
```
\*\*任务控制块在内核中是应用的管理单位。
#### 任务管理器
全局的任务管理器来管理这些任务控制块：
```
// os/src/task/mod.rs
pub struct TaskManager {
    num_app: usize,
    inner: UPSafeCell<TaskManagerInner>,
}

struct TaskManagerInner {
    tasks: [TaskControlBlock; MAX_APP_NUM],
    current_task: usize,
}
```
字段 num_app 表示应用数目，它在 TaskManager 初始化后将保持不变； 
而包裹在 TaskManagerInner 内的任务控制块数组 tasks，以及正在执行的应用编号 current_task 会在执行过程中变化。

初始化 TaskManager 的全局实例 TASK_MANAGER：
```
 1// os/src/task/mod.rs
 2
 3lazy_static! {
 4    pub static ref TASK_MANAGER: TaskManager = {

    //调用 loader 子模块提供的 get_num_app 接口获取链接到内核的应用总数
 5        let num_app = get_num_app();

 6        let mut tasks = [TaskControlBlock {
 7            task_cx: TaskContext::zero_init(),
 8            task_status: TaskStatus::UnInit,
 9        }; MAX_APP_NUM];

        //依次对每个任务控制块进行初始化，将其运行状态设置为 Ready ，
        并在它的内核栈栈顶压入一些初始化 上下文，然后更新它的 task_cx
10        for (i, t) in tasks.iter_mut().enumerate().take(num_app) {
11            t.task_cx = TaskContext::goto_restore(init_app_cx(i));
12            t.task_status = TaskStatus::Ready;
13        }

        //创建 TaskManager 实例并返回。
14        TaskManager {
15            num_app,
16            inner: unsafe {
17                UPSafeCell::new(TaskManagerInner {
18                    tasks,
19                    current_task: 0,
20                })
21            },
22        }
23    };
24}
```
#### 实现 sys_yield 和 sys_exit
sys_yield 的实现用到了 task 子模块提供的 suspend_current_and_run_next 接口，暂停当前的应用并切换到下个应用。
```
// os/src/syscall/process.rs
use crate::task::suspend_current_and_run_next;
pub fn sys_yield() -> isize {
    suspend_current_and_run_next();
    0
}
```
suspend_current_and_run_next的实现
```
// os/src/task/mod.rs
pub fn suspend_current_and_run_next() {
    TASK_MANAGER.mark_current_suspended();
    TASK_MANAGER.run_next_task();
}
```

sys_exit 基于 task 子模块提供的 exit_current_and_run_next 接口，它的含义是退出当前的应用并切换到下个应用：
```
// os/src/syscall/process.rs
use crate::task::exit_current_and_run_next;
pub fn sys_exit(exit_code: i32) -> ! {
    println!("[kernel] Application exited with code {}", exit_code);
    exit_current_and_run_next();
    panic!("Unreachable in sys_exit!");
}
```
exit_current_and_run_next的实现
```
// os/src/task/mod.rs
pub fn exit_current_and_run_next() {
    TASK_MANAGER.mark_current_exited();
    TASK_MANAGER.run_next_task();
}
```
它们都是先修改当前应用的运行状态，然后尝试切换到下一个应用。
```
1// os/src/task/mod.rs
2
3impl TaskManager {
4    fn mark_current_suspended(&self) {
5        let mut inner = self.inner.exclusive_access();
6        let current = inner.current_task;
7        inner.tasks[current].task_status = TaskStatus::Ready;
8    }
9}
```
以 mark_current_suspended 为例。首先获得里层 TaskManagerInner 的可变引用，然后修改任务控制块数组 tasks 中当前任务的状态。
run_next_task 的实现：
```
 1// os/src/task/mod.rs
 2
 3impl TaskManager {
 4    fn run_next_task(&self) {
 5        if let Some(next) = self.find_next_task() {
 6            let mut inner = self.inner.exclusive_access();
 7            let current = inner.current_task;
 8            inner.tasks[next].task_status = TaskStatus::Running;
 9            inner.current_task = next;
10            let current_task_cx_ptr = &mut inner.tasks[current].task_cx as *mut TaskContext;
11            let next_task_cx_ptr = &inner.tasks[next].task_cx as *const TaskContext;
12            drop(inner);
13            // before this, we should drop local variables that must be dropped manually
14            unsafe {
15                __switch(current_task_cx_ptr, next_task_cx_ptr);
16            }
17            // go back to user mode
18        } else {
19            panic!("All applications completed!");
20        }
21    }
22
23    fn find_next_task(&self) -> Option<usize> {
24        let inner = self.inner.exclusive_access();
25        let current = inner.current_task;
26        (current + 1..current + self.num_app + 1)
27            .map(|id| id % self.num_app)
28            .find(|id| inner.tasks[*id].task_status == TaskStatus::Ready)
29    }
30}
```
run_next_task 会调用 find_next_task 方法尝试寻找一个运行状态为 Ready 的应用并获得其 ID 。 如果找不到， 说明所有应用都执行完了， find_next_task 将返回 None ，内核 panic 退出。 如果能够找到下一个可运行应用，就调用 __switch 切换任务。切换任务之前，要手动 drop 掉获取到的 TaskManagerInner 可变引用。 因为函数还没有返回， inner 不会自动销毁。只有令 TASK_MANAGER 的 inner 字段回到未被借用的状态，下次任务切换时才能再借用。

\*\*运行状态变化图
![image-6](https://github.com/Kalining/code_repository/assets/148835940/8eb98eaa-bb70-4fff-a0a9-fd0e537e5e1a)

#### 第一次进入用户态
在初始化任务控制块时：
```
// os/src/task/mod.rs
for (i, t) in tasks.iter_mut().enumerate().take(num_app) {
    t.task_cx = TaskContext::goto_restore(init_app_cx(i));
    t.task_status = TaskStatus::Ready;
}
```
init_app_cx 在 loader 子模块中定义，它向内核栈压入了一个 Trap 上下文，并返回压入 Trap 上下文后 sp 的值。 \*\*这个 Trap 上下文的构造方式与第二章相同。

goto_restore 保存传入的 sp，并将 ra 设置为 __restore 的入口地址，构造任务上下文后返回。任务管理器中各个应用的任务上下文就得到了初始化。
```
// os/src/task/context.rs

impl TaskContext {
    pub fn goto_restore(kstack_ptr: usize) -> Self {
        extern "C" { fn __restore(); }
        Self {
            ra: __restore as usize,
            sp: kstack_ptr,
            s: [0; 12],
        }
    }
}
```
在 rust_main 中调用 task::run_first_task 来执行第一个应用：
```
 1// os/src/task/mod.rs
 2
 3fn run_first_task(&self) -> ! {
 4    let mut inner = self.inner.exclusive_access();
 5    let task0 = &mut inner.tasks[0];
 6    task0.task_status = TaskStatus::Running;
 7    let next_task_cx_ptr = &task0.task_cx as *const TaskContext;
 8    drop(inner);
 9    let mut _unused = TaskContext::zero_init();
10    // before this, we should drop local variables that must be dropped manually
11    unsafe {
12        __switch(&mut _unused as *mut TaskContext, next_task_cx_ptr);
13    }
14    panic!("unreachable in run_first_task!");
15}
```
显式声明了一个 _unused 变量，并将它的地址作为第一个参数传给 __switch(为了避免其他数据被覆盖。)在 __switch 中恢复 sp 后， sp 将指向 init_app_cx 构造的 Trap 上下文，后面就回到第二章的情况了。 此外， __restore 的实现需要做出变化：不再需要 在开头 mv sp, a0 了。因为在 __switch 之后，sp 就已经正确指向了我们需要的 Trap 上下文地址。
### 分时多任务系统
现代的任务调度算法基本都是抢占式的，它要求每个应用只能连续执行一段时间，然后内核就会将它强制性切换出去。 一般将 时间片 作为应用连续执行时长的度量单位，每个时间片可能在毫秒量级。 简单起见使用 时间片轮转算法 (RR, Round-Robin) 来对应用进行调度。
#### 时钟中断与计时器
实现调度算法需要计时。RISC-V 要求处理器维护时钟计数器 mtime，还有另外一个 CSR mtimecmp 。 一旦计数器 mtime 的值超过了 mtimecmp，就会触发一次时钟中断。

运行在 M 特权级的 SEE 已经预留了相应的接口，基于此编写的 get_time 函数可以取得当前 mtime 计数器的值；
```
// os/src/timer.rs
use riscv::register::time;
pub fn get_time() -> usize {
    time::read()
}
```
在 10 ms 后设置时钟中断的代码如下：
```
 1// os/src/sbi.rs
 2
 3const SBI_SET_TIMER: usize = 0;
 4
 5pub fn set_timer(timer: usize) {
 6    sbi_call(SBI_SET_TIMER, timer, 0, 0);
 7}
 8
 9// os/src/timer.rs
10
11use crate::config::CLOCK_FREQ;
12const TICKS_PER_SEC: usize = 100;
13
14pub fn set_next_trigger() {
15    set_timer(get_time() + CLOCK_FREQ / TICKS_PER_SEC);
16}
```
5:sbi 子模块有一个 set_timer 调用，用来设置 mtimecmp 的值。

14:timer 子模块的 set_next_trigger 函数对 set_timer 进行了封装， 它首先读取当前 mtime 的值，然后计算出 10ms 之内计数器的增量，再将 mtimecmp 设置为二者的和。 这样，10ms 之后一个 S 特权级时钟中断就会被触发。

增量的计算方式: CLOCK_FREQ 是一个预先获取到的各平台不同的时钟频率，单位为赫兹，也就是一秒钟之内计数器的增量。 它可以在 config 子模块中找到。10ms 的话只需除以常数 TICKS_PER_SEC 也就是 100 即可。

设计一个函数满足一些计时的需求：
```
// os/src/timer.rs
const MICRO_PER_SEC: usize = 1_000_000;
pub fn get_time_us() -> usize {
    time::read() / (CLOCK_FREQ / MICRO_PER_SEC)
}
```
timer 子模块的 get_time_us 可以以微秒为单位返回当前计数器的值。
新增一个系统调用，使应用能获取当前的时间：
```
/// 功能：获取当前的时间，保存在 TimeVal 结构体 ts 中，_tz 在我们的实现中忽略
/// 返回值：返回是否执行成功，成功则返回 0
/// syscall ID：169
fn sys_get_time(ts: *mut TimeVal, _tz: usize) -> isize;
```
结构体 TimeVal 的定义如下，内核只需调用 get_time_us 即可实现该系统调用。
```
// os/src/syscall/process.rs
#[repr(C)]
pub struct TimeVal {
    pub sec: usize,
    pub usec: usize,
}
```
#### RISC-V 架构中的嵌套中断问题
默认情况下，当 Trap 进入某个特权级之后，在 Trap 处理的过程中同特权级的中断都会被屏蔽。

+ 当 Trap 发生时，sstatus.sie 会被保存在 sstatus.spie 字段中，同时 sstatus.sie 置零， 这也就在 Trap 处理的过程中屏蔽了所有 S 特权级的中断；
+ 当 Trap 处理完毕 sret 的时候， sstatus.sie 会恢复到 sstatus.spie 内的值。

\*\*如果不去手动设置 sstatus CSR ，在只考虑 S 特权级中断的情况下，是不会出现嵌套中断的。
#### 抢占式调度
有了时钟中断和计时器，实现抢占式调度：
```
// os/src/trap/mod.rs
match scause.cause() {
    Trap::Interrupt(Interrupt::SupervisorTimer) => {
        set_next_trigger();
        suspend_current_and_run_next();
    }
}
```
在 trap_handler 函数下新增一个分支，触发了 S 特权级时钟中断时，重新设置计时器， 调用 suspend_current_and_run_next 函数暂停当前应用并切换到下一个。

为了避免 S 特权级时钟中断被屏蔽，在执行第一个应用前调用 enable_timer_interrupt() 设置 sie.stie， 使得 S 特权级时钟中断不会被屏蔽；再设置第一个 10ms 的计时器。
```
 1// os/src/main.rs
 2
 3#[no_mangle]
 4pub fn rust_main() -> ! {
 5    // ...
 6    trap::enable_timer_interrupt();
 7    timer::set_next_trigger();
 8    // ...
 9}
10
11// os/src/trap/mod.rs
12
13use riscv::register::sie;
14
15pub fn enable_timer_interrupt() {
16    unsafe { sie::set_stimer(); }
17}
```
### 总结
![第三章](https://github.com/Kalining/code_repository/assets/148835940/0ce337c4-9177-45d2-80b7-ac72174871dd)
